[GENERAL]

# Device to train models on. Options are: [cpu | cuda]
device = cuda

[MODEL_PARAMETERS]

# Number of classes predicted by model
n_classes = 2
# Output size of embedding layer
embedding_size = 39
# Number of output channels of convolutional layer
conv_channels = 128
# Dropout rate
dropout_rate = 0.25

# Output size of bidirectional LSTM layer
blstm_output_size = 256
# Output size LSTM layer
lstm_output_size = 256

# Activation function. Options are: [relu | tanh | elu | leakyrelu]
activation = relu


[TRAINING]

# Batch size
batch_size = 1000
# Length of classified protein fragment
patch_size = 33
#patch_size = 33
# Step taken between fragments
patch_stride = 1
# Substitution matrix to perform augmentations with. Options are [BLOSUMXX | PAMXXX]
substitution_matrix = BLOSUM45
# Factor that regulates augmentations. Greater - more substitutions, lower - less
replacement_proba_factor = 250
# Fraction of positive class peptides in batch
pos_proba = 0.1
# Fraction of antipos peptides in batch
antipos_proba = 0.5
# Whether to use scheduler or not
use_scheduler = True
# Scheduler type. Options are: [reduce_on_plateau | step]
scheduler_type = step
# Scheduler factor
scheduler_factor = 0.5
# Scheduler patience (for reduce_on_plateau scheduler only)
scheduler_patience = 10
# Scheduler interval (for step scheduler only)
scheduler_interval = 25

# Optimizer. Options are: [adam | rmsprop | adamw]
optimizer = adam
# Learning rate
lr = 0.0047474
